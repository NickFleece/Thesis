\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Literature Review}{6}{chapter.28}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter3}{{3}{6}{Literature Review}{chapter.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Image Classification}{6}{section.29}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Optical Flow}{6}{section.30}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}CNN Based Models}{6}{section.31}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}CNN + LSTM Models}{6}{subsection.32}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces An example structure of a simple CNN-LSTM based model, each individual frame being individually fed into the CNN, and then passed to a LSTM.\relax }}{7}{figure.caption.33}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:cnn-lstm}{{3.1}{7}{An example structure of a simple CNN-LSTM based model, each individual frame being individually fed into the CNN, and then passed to a LSTM.\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Action recognition structure for the LRCN model. \blx@tocontentsinit {0}\cite {LRCNS}\relax }}{8}{figure.caption.34}\protected@file@percent }
\newlabel{fig:lrcn-ar}{{3.2}{8}{Action recognition structure for the LRCN model. \cite {LRCNS}\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Overview of the Beyond Short Snippets: Deep Networks for Video Classification model \blx@tocontentsinit {0}\cite {beyondshortsnippets}\relax }}{9}{figure.caption.35}\protected@file@percent }
\newlabel{fig:beyondoverview}{{3.3}{9}{Overview of the Beyond Short Snippets: Deep Networks for Video Classification model \cite {beyondshortsnippets}\relax }{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Deep LSTM architecture utilized by \blx@tocontentsinit {0}\cite {beyondshortsnippets} in the feature aggregation step as shown in figure \ref  {fig:beyondoverview}.\relax }}{9}{figure.caption.36}\protected@file@percent }
\newlabel{fig:deeplstm}{{3.4}{9}{Deep LSTM architecture utilized by \cite {beyondshortsnippets} in the feature aggregation step as shown in figure \ref {fig:beyondoverview}.\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}3D CNN Models}{10}{subsection.37}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces The original 3D-CNN action recognition model architecture proposed by \blx@tocontentsinit {0}\cite {3DCNN-ActionRecognition}, containing 3 convolutional layers, two subsampling layers, and one fully connected layer\relax }}{10}{figure.caption.38}\protected@file@percent }
\newlabel{fig:original3dcnn}{{3.5}{10}{The original 3D-CNN action recognition model architecture proposed by \cite {3DCNN-ActionRecognition}, containing 3 convolutional layers, two subsampling layers, and one fully connected layer\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces The model architecture used in the I3D paper \blx@tocontentsinit {0}\cite {i3d}, where the Inflated Inception-V1 architecture (left) and it's detailed submodule (right) are shown.\relax }}{11}{figure.caption.39}\protected@file@percent }
\newlabel{fig:I3D}{{3.6}{11}{The model architecture used in the I3D paper \cite {i3d}, where the Inflated Inception-V1 architecture (left) and it's detailed submodule (right) are shown.\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Model Evolution}{11}{section.40}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces The original transformer model proposed in \blx@tocontentsinit {0}\cite {transformer_og}, the image is split into fixed-size patches, linearly embed them, and add positional embeddings. It is then fed into a standard Transformer Encoder architecture.\relax }}{11}{figure.caption.41}\protected@file@percent }
\newlabel{fig:transformerActionRecognition}{{3.7}{11}{The original transformer model proposed in \cite {transformer_og}, the image is split into fixed-size patches, linearly embed them, and add positional embeddings. It is then fed into a standard Transformer Encoder architecture.\relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Example feature outputs of how a transformer utilizes attention to focus on the main subject of a video in order to greater identify actions as shown in \blx@tocontentsinit {0}\cite {transformer_og}\relax }}{12}{figure.caption.42}\protected@file@percent }
\newlabel{fig:attentionExample}{{3.8}{12}{Example feature outputs of how a transformer utilizes attention to focus on the main subject of a video in order to greater identify actions as shown in \cite {transformer_og}\relax }{figure.caption.42}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Datasets}{13}{section.43}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Kinetics}{13}{subsection.44}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}JHMDB}{13}{subsection.45}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Pose Detection}{13}{section.46}\protected@file@percent }
\newlabel{sec:pose-detection}{{3.6}{13}{Pose Detection}{section.46}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}OpenPose}{13}{subsection.47}\protected@file@percent }
\newlabel{sec:openpose}{{3.6.1}{13}{OpenPose}{subsection.47}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Pose-Based Action Recognition}{13}{section.48}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.1}Intermediate Representations}{13}{subsection.49}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces The illustration of the PoTion representation \blx@tocontentsinit {0}\cite {potion}. The input joint heatmaps are colored based on their time in the frame, and the frames are then concatenated to form the final movement of the joint throughout the video.\relax }}{14}{figure.caption.50}\protected@file@percent }
\newlabel{fig:potion-architecture}{{3.9}{14}{The illustration of the PoTion representation \cite {potion}. The input joint heatmaps are colored based on their time in the frame, and the frames are then concatenated to form the final movement of the joint throughout the video.\relax }{figure.caption.50}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces The colourization method utilized by the PoTion model \blx@tocontentsinit {0}\cite {potion}. As the frame index moves throughout the video, the colour of the joint shifts from one to another. This can be done for any amount of colours, denoted by C, the figure shows examples for C=2 and C=3, but the same logic holds for more than 3.\relax }}{15}{figure.caption.51}\protected@file@percent }
\newlabel{fig:potion-colourization}{{3.10}{15}{The colourization method utilized by the PoTion model \cite {potion}. As the frame index moves throughout the video, the colour of the joint shifts from one to another. This can be done for any amount of colours, denoted by C, the figure shows examples for C=2 and C=3, but the same logic holds for more than 3.\relax }{figure.caption.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces \relax }}{15}{figure.caption.52}\protected@file@percent }
\newlabel{fig:PA3D}{{3.11}{15}{\relax }{figure.caption.52}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces \relax }}{16}{figure.caption.53}\protected@file@percent }
\newlabel{fig:EHPI}{{3.12}{16}{\relax }{figure.caption.53}{}}
\@setckpt{Chapters/Chapter3}{
\setcounter{page}{17}
\setcounter{equation}{0}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{7}
\setcounter{subsection}{1}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{12}
\setcounter{table}{0}
\setcounter{LT@tables}{1}
\setcounter{LT@chunks}{1}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{53}
\setcounter{maxnames}{3}
\setcounter{minnames}{3}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{0}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{blx@maxsegment@0}{0}
\setcounter{blx@sectionciteorder@0}{53}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{cbx@tempcnta}{0}
\setcounter{cbx@tempcntb}{22}
\setcounter{cbx@tempcntc}{0}
\setcounter{cbx@tempcntd}{-1}
\setcounter{Item}{2}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{34}
\setcounter{section@level}{2}
}
